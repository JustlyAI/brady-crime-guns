
# Post #1 on NotebookLM
<post_1>
NotebookLM: When Your Project Needs More Than a Chatbot

 

As we continue to expand our AI toolkit, one platform stands out for its unique ability to transform how teams collaborate around complex document sets: Google NotebookLM Enterprise. Registered users access it here.

 

Why NotebookLM Is Different

 

While we have many excellent AI tools at our disposal, NotebookLM fills a critical niche that no other platform addresses quite as effectively:

 

Build Persistent Document Repositories

 

NotebookLM is the only tool in our portfolio that allows you to create and maintain a curated collection of source documents that persists across sessions. Unlike chat-based tools where context resets, your NotebookLM workspace retains all sources and analysis, making it ideal for long-running matters.

 

True Team Collaboration

 

Multiple team members can contribute sources, notes and reports to the same notebook (accessed in the Studio tab). This creates a shared knowledge base where colleagues can all build on each other's research and analysis.

 

Unique Analytical Features

 

NotebookLM offers capabilities you won't find elsewhere in our toolkit:

 

Audio Podcast: Generate conversational deep-dives on your sources
Mind Map: Visualize relationships between key concepts across sources
Timeline View: Automatically extract and visualize chronological information
Study Guide: Create structured learning materials from complex documents
FAQ Generation: Automatically surface key questions and answers
More features coming soon
 

Intelligent Briefing Reports

 

Generate comprehensive briefing documents based on any combination of sources in your notebook. Customization options are expanding, allowing you to tailor reports to specific matter types and client needs.

 

Reminders

 

Google NotebookLM is approved for use with client and firm data. 

 

Remember to always fact-check legal research and confirm that you may use AI for specific clients and client matters.

 

Please refer to Responsible Use of AI SharePoint and the Global IT Use Policy for all guidelines.

 

Getting Started

 

Ready to try NotebookLM Enterprise for your next matter? Access is simple:

Submit a ServiceNow request to get provisioned with full enterprise access, which ensures client data protection and team collaboration features.

 

Request Google NotebookLM Enterprise - Tech Service Portal →

 

Ready to dive deeper? Our NotebookLM Enterprise SharePoint site houses training materials, playbooks, and tips from power users across the firm.

 

---


Questions about NotebookLM or other AI tools? Visit the support page or contact the Innovation Team at GIO_Support@freshfields.com. If you need any technical support, the Global IT Service Desk is available via the Service Portal or at +44 161 880 6666.

see less
</post_1>


# Post #2 on Context Engineering
<post_2>
NotebookLM as Context Engineer

 

Last week, we introduced NotebookLM as the platform for persistent document repositories and team collaboration. This week, we explore how NotebookLM serves as your context engineering workhorse - the central hub for building and maintaining the context that dramatically enhances all your AI interactions.

 

This approach is geared toward advanced users or those looking to think creatively about integrating AI more deeply into their practice. While these principles apply across all practice areas, let's explore how a US civil litigation (DR) team might apply them in practice. 

 

Your Context Command Center

 

Upload your key matter documents to NotebookLM - pleadings, witness statements, expert reports, key correspondence. Then use NotebookLM's synthesis capabilities to generate structured notes that become your matter context. These notes, made widely available to the team, could be reused in any AI interaction on your matter.

 

Instead of repeatedly explaining your case to different AI tools, you build your context once in NotebookLM, refine it collaboratively with your team, and then use it across platforms - in Copilot, Freshfields Chat, or other AI tools.

 

What Is Context Engineering?

 

You've heard of prompt engineering--crafting the perfect question for AI. But the quality of your AI output depends far more on context than prompts. The models we work with can process vast amounts of information - far more than the content of a single, task-specific prompt.

 

Context engineering is the discipline of systematically building and maintaining the complete information environment your AI needs to succeed. It's the difference between asking an AI to "review this document" versus giving it the background to review it like a senior litigator would, complete with the case's procedural posture, your team's strategy, and the specific issues that matter most.

 

This approach transforms AI from a basic assistant into a sophisticated legal tool that understands your matter as deeply as your team does.

 

A Practical Framework: 4 Components for Dispute Resolution

 

Consider how a litigation team might organize their context into four essential components. This is one approach - you'll discover what works best for your practice:

 

1. System Context / Personal Instructions

You are a Disputes Resolution associate at Freshfields.
Follow [jurisdiction] rules. Maintain privilege.
Cite sources. Flag uncertainties.
2. Matter Context

Case: [Client] v. [Opponent]
Court: [Where and which judge]
Claims: [Core disputes]
Procedural Milestones: [E.g., motion to dismiss denied]
3. Task Context

Current Task: [What you're doing now]
Relevant information: [Facts to consider in analysis]
Output: [What to produce]
Success Criteria: [What good looks like]
4. Strategic Context

Case Theory: "[One sentence summary]"
Strengths: [Our best arguments]
Vulnerabilities: [What to watch for]
Red Lines: [What never to concede]

Your team might find different components work better, or you might need additional elements specific to your practice area. The key is to start experimenting and refine based on what delivers results.

 

Organizing Your Context Library

 

Each context component can be saved as a separate, reusable text file or Word document that you maintain throughout your matter:

 

- System_Context.txt - Your standard firm and personal requirements (rarely changes)

- Matter_Context_[CaseName].txt - Case-specific details (update regularly)

- Task_Context_Template.txt - Reusable template for different tasks

- Strategic_Context_[CaseName].txt - Case strategy (update as needed)

 

This modular approach lets you mix and match context components as needed. Running document review? Attach System + Matter + Task contexts. Drafting a motion? Add Strategic context. Meeting with client? Maybe just Matter + Strategic.

 

This systematic approach delivers consistent, high-quality AI outputs across your entire team - whether you're building shared context libraries or developing your own personal workflow optimization.

 

Building Your Context Documents with NotebookLM

 

NotebookLM excels at generating the content for these reusable context files:

 

Step 1: Create Your Matter Notebook

 

Upload your core documents--complaint, answer, key motions, important correspondence. NotebookLM maintains these persistently, unlike chat tools that reset.

 

Step 2: Generate Context Components

 

Use NotebookLM's chat feature to create the content for each context document:

 

Ask it to extract key dates and deadlines for your Matter Context document
Have it identify strengths and weaknesses for your Strategic Context file
Generate case theory options based on your uploaded pleadings
 

Step 3: Refine and Save

 

Copy the generated context from NotebookLM into your text files or Word documents. Within NotebookLM, individual notes can be highly specific and modularized, and later exported or copied and combined into reusable context. Your team can access the same notebook, reviewing and refining the context together.

 

Step 4: Maintain Living Documents

 

As new filings arrive - depositions, discovery responses, court orders - add them to NotebookLM and update your context documents. Your context evolves with your case.

 

Using Your Context Documents Across Platforms

 

Once you've created your context documents using NotebookLM, you can use them consistently across all AI interactions:

 

Microsoft Copilot: Start your Copilot sessions by attaching relevant context documents for informed responses across all your Copilot research and Microsoft 365 work.
Freshfields Chat: Include your context files at the beginning of document analysis sessions for improved accuracy and relevance.
 

For whatever tools are used in your daily work, your context documents enhance the consistency, focus, and quality of outputs.

 

Discovering Your Own Approach

 

Experiment with what works for your practice. Some teams might build shared context libraries, while individual lawyers might develop personal context systems that reflect their personal style and preferences for working with AI. The key is to start building structured context now and observe how it transforms your AI interactions, and to perfect a system over time, much like we might have perfected systems for deposition prep or client updates in the past.

 

Context Validation

 

Always verify NotebookLM-generated context against source documents, especially for dates, dollar amounts, and legal citations. NotebookLM is excellent at synthesis, but human verification remains essential for accuracy.

 

---

 

Access NotebookLM Enterprise through the NotebookLM Enterprise SharePoint.

 

Questions about NotebookLM or other AI tools? Visit the support page or contact the Innovation Team at GIO_Support@freshfields.com. If you need any technical support, the Global IT Service Desk is available via the Service Portal or at +44 161 880 6666.


</post_2>


Post #3 on Voice Access


<post_3>

Voice Access: Think Out Loud, Let AI Capture It

 

Voice is how we naturally process complex ideas—talking through arguments, articulating strategy, thinking out loud. 

 

Did you know that your Windows 11 computer already has Voice Access built in? Turn it on, and your computer listens. Turn it off, and it stops. No special software required.

 

Just Chat With It

 

When you're developing case strategy or working through complex ideas, typing interrupts your flow. Voice Access lets you think out loud—articulate your case theory, talk through witness concerns, capture strategic insights right after a meeting. 

 

Given AI's analytical capabilities, talking naturally can be just as effective as a carefully crafted prompt. The AI doesn't need perfect syntax—it needs the right context. Speak your thoughts, provide the relevant background, and let the AI synthesize it. Less time formatting, more time thinking strategically.

 

Setting Up Voice Access on Windows 11

 

Enable Voice Access

 

Open Settings (Windows + I)
Go to Accessibility > Speech
Toggle Voice Access to On
Download the speech model when prompted
 

Configure Your Microphone

 

Windows will guide you through mic selection and testing. Built-in or USB microphones work fine—no special equipment needed.

 

Basic Commands

 

Once active, you'll see a Voice Access bar at the top of your screen.

 

Dictation: Simply speak your text. Punctuation works naturally: "Type hello comma this is my first test period"

 

Pause and resume:

"Voice access sleep" or "Turn off microphone" (pause listening)
"Wake up" (resume)
 

Control commands:

"Open Word"
"Click Start"
"Scroll down"
 

Reminders

 

Voice Access is a Windows 11 accessibility feature—no additional software required. While it is effective, always carefully review and edit dictated content.

 

Happy chatting!
</post_3>

Post 4: AI Academy+: Enhance prompt

<post_4>
AI Academy+: Learning to Prompt with FF Chat

 

You're staring at a complex document set and need to extract key terms from a lengthy contract. You know what you want but explaining it clearly to AI feels like drafting a motion—tedious and time-consuming.

 

There's a better way, and it's already built into the tools you're using.

At last week's AI Academy session on Effective Prompting, Nick Cooper shared a simple but powerful tip: always look for ways to enhance or improve your prompt. As he emphasized live, this isn't just good advice—it's been custom-built into AI Toolkit Chat (or, as I like to call it, FF Chat).

 

Watch the full presentation, Effective Prompting, here (slides).

 

Past Recordings and Session Materials are available from the AI Academy.

 

Press Button > Improve Prompt > Better Output

 

FF Chat has a homegrown feature designed specifically for our environment: an "enhanced prompt" button. Click it, and your prompt is automatically refined—adding clarity, structure, and relevant context that improves your results.


What makes the feature particularly useful is that you can edit the enhanced prompt before sending it. This means you're not locked into the AI's suggestions. You can trim, adjust, or add details to match your specific needs. Think of it as having a prompting coach that offers suggestions you can accept, modify, or ignore.

 

Combining Voice and Enhanced Prompts

 

FF Chat also supports voice input, which pairs naturally with the enhanced prompt feature:

 

Speak your prompt - Talk through what you need, thinking out loud as you would with a colleague
Click enhance - Let the tool refine your spoken prompt into structured text
Edit as needed - Adjust the enhanced version to get exactly what you want
 

This workflow is especially useful when you're working through complex ideas. It's usually easier to cut and edit than it is to write from scratch. Start with more detail, then trim.

 

Developing Your Prompting Skills

 

The enhanced prompt is also an excellent learning tool. Each time you use it, you see how effective prompts are structured. Over time, you'll develop intuition for:

 

What level of detail works best
How to structure complex requests
When context matters most
Which approaches get better results
 

Some professionals find they gradually need the tool less as they internalize these patterns. Others continue using it to save time. Both approaches are valid—experiment and discover what works for your practice.

 

Try It Today

 

Whether you're new to AI tools or looking to refine your technique, FF Chat's enhanced prompt feature offers a practical way to improve.


The more you practice, the better your prompting becomes.

 

---

Questions about FF Chat or other AI tools? Contact the Innovation Team at GIO_Support@freshfields.com. For technical support, reach the Global IT Service Desk via the Service Portal or at +44 161 880 6666
</post_4>


---
post 5: AI Academy +: Search and Synthesis

<post_5>
AI Academy+: Search and Synthesis

 

The latest AI Academy session on Use Case Training: Research introduced you to the full landscape of AI research tools—from public platforms like ChatGPT and Gemini to Copilot in Edge, the Freshfields AI Toolkit, and NotebookLM Enterprise. We covered deep research capabilities, tool selection, and when to use what.

 

Today, we're double-clicking into one critical insight from that session: the difference between search and synthesis, and how NotebookLM fits into your research workflow.

 

Watch the full presentation, Use Case Training: Research, here (slides).

 

Past Recordings and Session Materials are available from the AI Academy.

 

 

The Core Distinction

 

As we demonstrated during training, NotebookLM is fundamentally different from the other research tools. It's your synthesis engine, not your search engine. Understanding this distinction transforms how you approach research.

 

The Research Workflow: Two Distinct Phases

 

Here's how the various tools at our disposal work together:

 

Phase 1: Search

 

Use the tools we covered that are optimized for comprehensive searching and deep research:

 

Copilot in Edge - Convenient for quick queries directly in your browser
Public AI platforms - Perplexity, ChatGPT, Gemini for broad exploration and deep research
Freshfields AI Toolkit - With web search and reasoning enabled for complex research (Gemini only)
Legal research platforms - Lexis+, CoCounsel, Bloomberg Law
Practice-specific resources - Your specialized databases and research tools (e.g., Intelligize).
 

These platforms excel at casting wide nets, following research threads, and pulling together information from across the web and legal databases. Let them do what they're built for: comprehensive discovery.

 

Phase 2: Synthesis

 

Here's the insight we're emphasizing today: search is commodity, synthesis is competitive advantage.

 

Everyone has access to the same cases, the same statutes, the same research tools. What differentiates your work is how you synthesize that research—how you organize it, extract insights from it, build on it iteratively, and share understanding across your team.

 

Bring your search results into NotebookLM. Add outputs as sources—PDFs, documents, text files. NotebookLM builds a persistent, queryable repository specific to your matter that becomes smarter as you work.

 

Use the chat to drill into your sources, generate focused memos, and extract insights. Save valuable outputs as notes in the Studio tab—they become part of your permanent research record that your entire team can access.

 

When you need more sources, use the Discover sources feature. NotebookLM returns up to 10 relevant sources you can import directly. Your research repository grows organically, and because the notebook is dynamic, you can add, remove, and reorganize as your matter evolves.

 

Organizing Your Research Practice

 

Consider creating different notebooks for:

 

Matter-specific research (Case Name - Legal Research)
Topic-based research (Securities Litigation - Insider Trading Issues)
Ongoing monitoring (Regulatory Updates - [Your Practice Area])
 

Each notebook becomes a living research memo, continuously refined and expanded as needed.

 

Try the Two-Phase Approach

 

On your next significant research assignment:

 

Search broadly using the tools covered in the AI Academy research session—Copilot Web, deep research from the commercial tools, Freshfields AI Toolkit, or legal research platforms
Create a notebook named after the project (e.g., "Smith Litigation - Contract Interpretation")
Import search results as sources (PDFs, Word docs, or text files)
Synthesize through chat - drill into sources, generate memos, extract insights
Save valuable outputs as notes in the Studio tab
Share the notebook with team members who need access
Use Discover to find additional sources as questions arise
Keep it current as the matter develops
 

Reminders

 

Google NotebookLM Enterprise, Copilot for Edge (and Work), and the AI Toolkit are all approved for use with client and firm data. Always fact-check legal research outputs, verify case citations in Westlaw or Lexis, and confirm you may use AI tools for specific clients and matters.

 

For more relevant information, see our prior posts:


NotebookLM: When Your Project Needs More Than a Chatbot
NotebookLM as Context Engineer.
 

---

 

Questions about research workflows or NotebookLM? Contact the Innovation Team at GIO_Support@freshfields.com. For technical support, reach the Global IT Service Desk via the Service Portal or at +44 161 880 6666.
</post_5>


<post_6>
Building Prompt Libraries for the Context Engineering Era

 

Across the firm, teams are building prompt libraries—collections of effective prompts for common legal workflows. It's a smart move: well-crafted prompts save time and ensure consistency. But as we've explored in recent posts, context engineering principles reveal that the prompt itself is only part of the equation.

 

When context drives AI performance more than prompt wording, how should we structure our prompt libraries?

 

The answer reshapes what an effective prompt bank looks like.

 

The Industry Shift: From Prompts to Context

 

Throughout 2025, AI researchers and practitioners made a decisive terminology shift. In June, Andrej Karpathy (former OpenAI director) endorsed replacing "prompt engineering" with "context engineering," explaining that industrial-strength AI applications require "the delicate art and science of filling the context window with just the right information."

 

By September, Anthropic formalized this in their engineering blog: "Building with language models is becoming less about finding the right words for your prompts, and more about answering 'what configuration of context generates our model's desired behavior?'"

 

This aligns with what we've learned in our own effective prompting training: context beats examples. The most powerful element isn't finding perfect prompt wording—it's providing the complete information environment the AI needs.

 

For legal and business teams building prompt libraries, this means your collection of saved prompts is just one element within a broader context management system. The most effective "prompt bank" today is actually a context-enriched knowledge base.

 

Rethinking Prompt Bank Structure

 

First Generation prompt banks (through mid-2025) organized content simply: Use Case, Prompt, Output. Think about prompting as having a conversation with a colleague—but that colleague needs context to help you effectively.

 

The context engineering era demands additional dimensions for each prompt library entry:

 

Use Case Category

Contract review, due diligence, legal research, document drafting, etc.
 

The Prompt Itself

Your specific instruction or question
Remember: if it's too short, you'll get generic results; if it's too long, AI might not follow all your instructions
 

Required Context

What contextual information must accompany this prompt?
Specify matter context, jurisdiction, playbooks, or other essential background
 

Applicable Law

Relevant statutes and regulations
Key case law summaries
Treatise excerpts or legal framework text
 

Example Output

Sample results or attachments demonstrating successful use
Quality over quantity in examples
 

Validation Notes

What are the characteristics of a "high quality" response?
What are the different angles that need to be addressed?
Validation protocols for ensuring accuracy
 

The critical addition is that Required Context specification. This documents what contextual information must accompany the prompt for optimal results—and reminds users that successful AI interaction is about more than clever wording.

 

What Goes Into "Required Context"

 

When you document Required Context for a prompt bank entry, what specifically should you include? Based on our previous explorations of context engineering, that "Required Context" field might reference any combination of these context types:

 

System Context

Firm standards
Personal preferences
Situational awareness (e.g., "We take the aggressive end of the spectrum on discovery objections.") 
 

Matter + Strategic Context

Case or deal background
Key parties and relationships
Procedural posture or transaction stage
Case theory or deal objectives
Known strengths and vulnerabilities
 

Task Context

Specific objective for this analysis
Relevant documents or data sources
Success criteria and constraints
 

The Applicable Law field works alongside these context types, straddling the Matter, Strategic and Tasks contexts. Not every prompt needs all context types, but documenting which context each prompt requires ensures consistent, high-quality outputs across your team.

 

Quality Assurance in the Context Era

 

Prompting is a skill—you need to practice. Advanced AI models follow instructions more literally than previous generations, making explicit specifications essential.

 

But assembling context is where lawyers add the most value. Putting together context is a huge part of the work that lawyers can do well to ensure that accurate information is being fed to the LLM. Context requires careful review and validation—especially if being generated by LLMs themselves.

 

As we've discussed in a previous post (see NotebookLM as Context Engineer), AI tools can help synthesize and organize context from your source documents, but human verification remains essential. You understand the nuances of your matter, the strategic considerations, and the legal framework in ways AI cannot replicate.

 

Moving Forward

 

With today's rapidly developing AI capabilities, context is as important as—or more important than—the prompt itself.

 

Your prompt banks should reflect this reality. As you develop your prompt collections, document not just what to ask, but what context makes each question answerable. Build reusable context documents for common scenarios. Specify validation protocols for quality assurance.

 

Your collection of prompts becomes exponentially more valuable when each entry bridges the gap between the question and the complete information environment needed to answer it well. Professionals that master this integration will produce insights, analysis, and first drafts that weren't possible when prompts stood alone.

 

---

 

Questions about building context-aware prompt libraries? Contact the Innovation Team at GIO_Support@freshfields.com. For technical support, reach the Global IT Service Desk via the Service Portal or at +44 161 880 6666.

see less

</post_6>

<post_7>


5 Tips for Managing Context in Your AI Workflows

 

In our recent posts on context engineering, we've explored why context matters as much or more than prompt wording. Now let's get practical: how do you actually manage the context you're providing to AI tools?

 

When we say "context," we mean the additional information beyond your prompt—the text, files, or folders (where tools allow) that you provide to help the AI understand your matter and deliver better results.

 

Here are five essential tips—plus a bonus—for making your context work harder for you.

 

1. Own Your Context Window

 

Know your limits. ChatGPT is able to handle about 400,000 tokens of text; Gemini processes roughly 1 million (1 token = ~0.75 words). Understanding your available space helps you pack the right information.

 

Best practice: Don't fill more than half your context window on the first turn. Leave room for the AI's response and subsequent conversation. Think of it as keeping space on your desk for the work you're about to create together.

 

2. Convert to Text

 

Text files work better than PowerPoint slides or images. AI models process natural text more efficiently, making your context easier to parse and apply.

 

(Recent breakthrough research suggests images can be more information-dense than text. See DeepSeek-OCR: Revolutionary Context Compression. For most business conducted today, searchable text remains more practical.)

 

3. Distill for Information Density

 

Don't dump entire documents full of boilerplate and noise. Distill first. Summarize the key points. Include the signal, not the noise.

 

A 50-page agreement with three relevant sections? Extract and summarize those three sections rather than attaching the full document. Your AI will focus on what matters instead of wading through irrelevant content.

 

4. Group Similar Information

 

Here's a powerful technique: combine related context items into single documents using headers or demarcations to separate them.

 

Instead of attaching 10 separate case summaries, create one Key_Cases.txt file with each case separated by clear headers or XML tags:

## Case 1: Smith v. Jones
[Summary and relevant holdings]

## Case 2: Johnson v. Anderson  
[Summary and relevant holdings]

<xml_tag_example>

This content will be treated separately due to the opening and closing tags.

Hashtags for headings work just as well.

</xml_tag_example>
The AI understands these are distinct items within a single document. This approach is especially valuable when your platform limits the number of files you can attach—or when you want to keep your context organized and manageable.

 

The same principle applies to examples, precedents, or any grouped information. One well-structured document beats a dozen scattered files.

 

5. Keep Context Fresh

 

Creating great context once is valuable. Maintaining it is essential. As your matter evolves—new filings, changed deadlines, updated strategy—your context must evolve too.

 

Set regular review points: weekly for active matters, after major developments, before critical tasks. Stale context is worse than no context. Context rot undermines everything you've built.

 

This is where NotebookLM shines. As we explored in our previous post on NotebookLM as Context Engineer, it serves as your context command center—a persistent workspace where you can build, refine, and maintain living context documents as your matter progresses. Upload new developments, generate updated summaries, and keep your context files current without starting from scratch each time.

 

Bonus Tip: Reference Your Context

 

When you provide context files, explicitly reference them in your prompts:

I'm providing the following context documents:
Matter_Background.docx - case overview and procedural history
Strategic_Priorities.txt - our case theory and key objectives
Key_Precedents.txt - relevant case law

Please draft a motion for summary judgment consistent with this strategic framework..."
This explicit callout ensures the AI knows what context you've provided and how to use it.

 

In sum, apply these principles systematically. Know your limits, work in text, distill ruthlessly, group intelligently, and keep it fresh. You'll immediately notice clearer, more relevant outputs when your context is well-managed.

</post_7>

<post_8>
The MOST Important Context is... YOU!

 

In all this discussion of effective prompting and the concept of context, we haven't yet touched on the most important context of all: you. Your preferences, your style, how you work.

 

Here's a tip to end your week. Create a file with your preferences (your writing style, citation format, how you like memos structured). Call it HUMAN.txt or ME.txt or ROBERT.txt if your name is Robert. Attach it to every AI interaction. Now every output sounds like you without having to explain your preferences over and over.

 

The same approach works for anyone you interact with regularly. Your EA can maintain a file about your scheduling preferences and communication style. Associates can create files capturing how their supervising lawyers prefer work product. You can build files for key clients (their risk tolerance, communication preferences, business priorities) or judges you appear before frequently (their procedural preferences, writing style expectations, pet peeves). Reference these files in your prompts, and AI tailors outputs accordingly.

 

The models we use can handle massive amounts of context and are sophisticated enough to apply the right context to the right situation when you reference it properly. This is the path to truly personalized AI that adapts to you, your colleagues, your clients, and your practice. Start with one file this weekend. See what happens Monday
</post_8>

<post_9>
How to Get the Most Out of AI, Part 1: Priming

 

We've spent considerable time exploring context: building it, managing it, maintaining it. You understand that quality AI output depends on the information environment you create. Now let's address the crucial question: how do you ensure the AI actually understands the context you've provided before it starts substantive work?

 

This post introduces priming, a technique for complex matters requiring multi-turn conversations. Use it when work involves complex reasoning or multi-step analysis where the foundation matters as much as the output.

 

The Delegation Parallel

 

Think about briefing a colleague on a complex assignment. You provide case background and procedural posture, explain strategic considerations, and clarify output expectations. You confirm they understand before they begin.

 

Then you ask them to confirm their understanding. They reflect back the framework: "So we're analyzing under Delaware law, focusing on fiduciary duty claims, with special attention to Revlon given the sale context?"

 

You either confirm or correct: "Actually, we're more concerned with entire fairness because this is a controller transaction."

 

Only then does substantive work proceed within confirmed parameters.

 

Priming applies this same professional discipline to AI interactions.

 

What Is Priming?

 

Priming is the practice of establishing and confirming understanding before requesting substantive work. Rather than jumping directly to "draft the motion" or "analyze the contract," you first:

 

Articulate the context and constraints (your primer)
Request confirmation of understanding (the AI reflects back the framework)
Validate or correct, then proceed (ensure alignment, request substantive work)
 

This creates a confirmation loop that catches misalignment in turn 2, not after the AI generates unusable work product.

 

A Practical Framework

 

The threshold question: Would you brief a junior colleague before delegating this task? If yes, prime the AI the same way.

 

Here's how priming works for a transactional matter:

 

Turn 1: The Primer

Instead of asking directly for analysis, establish the framework:

I'm working on the [Client] acquisition of [Target]. Before we begin substantive analysis, let me establish the key parameters:

 

## Jurisdictional Context:

Delaware corporation acquisition
Board approval required under 251(c)
Shareholder vote anticipated

 

## Transaction Structure:

Cash and stock consideration
Management rollover contemplated
No financing contingency

 

## Strategic Priorities:

Speed to closing (target 60 days)
Minimize regulatory risk
Preserve key management relationships

 

## Output Expectations:

Consistent citation structure
Identify both legal requirements and strategic considerations
Flag areas requiring partner review

 

Please confirm your understanding of this framework before we proceed to specific analysis.

 

Turn 2: Confirmation

 

The AI reflects back its understanding:

 

"Based on your framework, I understand we're working on a Delaware statutory merger requiring board and stockholder approval, with mixed consideration and management participation. The priority is speed while managing regulatory exposure. I'll provide analysis with proper citations and distinguish legal requirements from strategic considerations, flagging partner-level issues. Is this correct?"

 

If the confirmation is accurate, you can proceed with substantive work immediately. 

 

If not, you correct and then proceed:

 

"Correct, except one clarification: management is rolling equity, not receiving new grants. This affects our disclosure obligations. With that adjustment, please analyze the disclosure obligations regarding management's rollover equity under Delaware law and SEC rules, focusing on timing and materiality thresholds."

 

Once alignment is confirmed, request your substantive analysis. This might happen in Turn 2 or require additional iteration first.

 

Why This Works

 

Priming forces clarity. In articulating the primer, you clarify your own thinking about the task, which improves outcomes.

 

It surfaces misalignment early. If the AI's confirmation reveals misunderstanding, you've caught it before wasted effort. Perhaps you mentioned "regulatory risk" but the AI focused on antitrust when you meant CFIUS. Better to correct this in turn 2.

 

It creates an audit trail. The primer plus confirmation documents what the AI was instructed to do. This becomes valuable if work is later questioned or needs to be resumed by a different team member.

 

It prevents the "garbage in, garbage out" problem. Without confirmation, you don't know whether the AI grasped relevant jurisdiction, applicable standards, client risk tolerance, output format, or citation style. Then you're surprised when output misses the mark.

 

Applying the Discipline

 

The discipline you apply to delegating to coworkers applies equally to AI. You wouldn't brief a colleague, skip confirmation, and hope for the best. Apply the same rigor with AI.

 

The investment in priming (typically one or two additional turns at the start) delivers returns across every subsequent interaction. You build on a confirmed foundation rather than correcting misalignment after the fact.

 

As we've established in previous posts, context is as important as the prompt itself. Priming ensures that carefully constructed context is actually understood before substantive work begins.

 

Looking Ahead

 

Part 2 of this series explores planning, breaking complex legal tasks into structured sequences that AI can execute systematically. Where priming ensures AI understands your framework, planning ensures it applies that framework methodically across multi-step workflows.

 

Together, priming and planning transform AI from a basic assistant into a sophisticated tool that understands your matter and executes complex analysis with minimal drift.
</post_9>


<post_10>

How to Get the Most Out of AI, Part 2: Planning

 

In Part 1, we explored priming—establishing and confirming the AI understands your context before it begins substantive work. You learned to brief AI the way you'd brief a junior colleague: provide framework, request confirmation, validate understanding, then proceed.

 

The Delegation Parallel Extended

 

But there's a crucial step between confirming understanding and starting work. When delegating a complex assignment to a colleague, you don't just establish context and say "go figure it out." You ask: "How would you tackle this?" They propose methodology. You refine it together. Then execution begins.

 

Planning does exactly this with AI—but you must explicitly request the approach. Unlike coworkers who naturally propose methodology, AI will dive straight into execution unless you ask for a plan first.

 

Your Planning Toolkit: Three Approaches

 

Different tasks call for different planning approaches:

 

1. Open Planning (Exploratory)

 

When to use: Novel legal issues, early matter development, exploring analytical angles

The instruction: "Before we start, create a detailed plan for how you'll approach this analysis."

Example: "We're evaluating whether our client's new business model raises securities law issues. Before analyzing the merits, outline your approach."

 

The AI proposes analyzing Howey test elements, examining SEC guidance, researching analogous models, identifying exemptions. You see its natural breakdown and refine from there.

 

2. Structured Planning (Systematic)

 

When to use: Multi-phase projects, high-volume work, need for consistency across reviewers or matters

The instruction: "Create a plan with these components: (1) Information you'll need, (2) Analytical framework, (3) Phases, (4) Deliverables."

Example: "We need to review 200 vendor contracts for data security and liability risks. Create a systematic plan covering categorization, risk assessment framework, review phases, and reporting."

 

This approach would be more likely to result in consistent treatment across all contracts.

 

3. Framework-Based Planning (Orthodox Legal)

 

When to use: Traditional legal analysis, established precedent frameworks

The instruction: "Outline your approach using [IRAC / Elements Test / Statutory Analysis] framework."

Example: "Analyze personal jurisdiction over this defendant using the elements test framework."

 

The AI structures its approach: controlling standard, constitutional elements (minimum contacts, relatedness, reasonableness), fact application, counterarguments, synthesis. Ensures proper legal reasoning from the start.

 

Planning in Action: Multi-Jurisdictional Regulatory Analysis

 

Here's how Structured Planning (Type 2) transforms a complex antitrust analysis.

Consider analyzing antitrust requirements for a software company acquisition across the US, EU, UK, Germany, and China.

 

Without Planning:

 

"Analyze the merger filing requirements and competitive issues for this acquisition across these five jurisdictions."

 

The AI dives in—jumping between HSR, EU Merger Regulation, and China's SAMR without structure. You get fragmented analysis requiring extensive reorganization.

 

With Planning:

 

Turn 1 - Prime: Establish the deal context ($850M software acquisition, both parties in enterprise software, need business mapping and competitive overlap analysis before signing). Request confirmation of understanding.

 

Turn 2 - Plan: "Before you begin, create a systematic plan with these components: (1) What information you'll need about the target business, (2) What analytical framework you'll apply for competitive assessment, (3) What phases you'll work through, (4) What deliverables you'll produce."

 

AI responds with structured plan:

 

"Phase 1: Target Business Mapping - revenue by jurisdiction, product lines, market segments Phase 2: Competitive Overlap Assessment - identify overlaps, assess market concentration, flag horizontal concerns Phase 3: Filing Requirements Analysis - HSR, EUMR, CMA, German, SAMR thresholds and timing Phase 4: Substantive Risk Assessment - approval likelihood per jurisdiction, required remedies, timeline dependencies Phase 5: Strategic Recommendations - filing strategy, sequencing, timing implications"

 

Turn 3 - Refine and Execute: You add foreign investment reviews (CFIUS, UK NSI) and cross-jurisdictional timing dependencies, then approve execution.

 

The AI now works systematically from business mapping through filing requirements to strategic recommendations. Each jurisdiction receives consistent treatment. The deliverable arrives organized and more likely to meet your expectations.

 

When to Use Planning

 

Not every AI interaction requires planning. For quick lookups or simple formatting tasks, it adds unnecessary friction. Use planning when:

 

The work involves multiple analytical steps or dependencies
You expect more than three turns with the AI
Consistency matters across documents, reviewers, or matters
 

If you'd brief a junior colleague on methodology before they start work, request a plan from AI.

 

The Prime > Plan > Run Framework

 

Priming and planning work together as a systematic approach to AI delegation:

 

Prime: Establish context and confirm understanding

Plan: Generate and validate methodology
Run: Execute within agreed framework

 

This mirrors how you'd delegate to a colleague—brief them, discuss approach, then let them execute. The difference: you must explicitly request each step with AI. It won't naturally propose methodology unless asked.

 

As AI capabilities evolve toward autonomous agents, this discipline becomes critical infrastructure. Professionals who master systematic delegation today will be positioned to effectively manage AI systems that handle complex multi-step tasks tomorrow.

 

---

 

Questions about planning or other advanced AI techniques? Contact the Innovation Team at GIO_Support@freshfields.com. For technical support, reach the Global IT Service Desk via the Service Portal or at +44 161 880 6666.
</post_10>

<post_11>
Markdown: The Lingua Franca of AI Communication

Over the past several weeks, we've explored context engineering—building the information architecture that enables AI to understand your work deeply. Now we turn to a key optimization that amplifies context engineering: markdown, the universal language LLMs speak most fluently.

If you've been following our series on context engineering, you've seen markdown syntax throughout our examples. That wasn't stylistic preference. Markdown is the primary format modern LLMs were trained to understand, and choosing it over other formats can dramatically improve your AI outputs.

Why LLMs "Think" in Markdown

Large language models process information through pattern recognition. When you provide context in markdown format, you're communicating through a structure the model has seen billions of times during training—in GitHub documentation, technical blogs, Stack Overflow, and countless other sources that shaped how these models understand information.

Consider what happens when you structure your prompt. Headers signal hierarchy and importance. Nested lists show relationships between ideas. Bold text emphasizes critical concepts. Code blocks preserve exact formatting. Each of these markdown elements sends explicit signals about how the LLM should interpret and weight the information you're providing.

This is fundamentally different from unstructured text. Plain paragraphs force the LLM to infer structure through content analysis, consuming computational resources and introducing ambiguity. Markdown makes the structure explicit, reducing errors and improving response quality.

Research confirms this isn't subjective. Recent studies show performance improvements of up to 40% on complex tasks when inputs are structured in markdown versus plain text, with the specific gains varying by model and task complexity. See Does Prompt Formatting Have Any Impact on LLM Performance? (November 2024).

The Power of Pattern and Structure

LLMs excel at recognizing and reproducing patterns. When you organize information systematically using markdown, you enable the model to map your intent with remarkable precision.

Separating complex information becomes trivial. Need to discuss five different client matters in a single prompt? Use H2 headers (##) to create clear boundaries:
## Matter 1: ABC Corp v. XYZ Inc.
[Relevant details about first matter]

## Matter 2: Securities Compliance Review
[Distinct information about second matter]







## Matter 3: M&A Due Diligence
[Third matter completely separate]
The LLM treats each section as a distinct information domain, preventing cross-contamination between matters—essential for maintaining the logical separation you need in legal work.

Nested hierarchy mirrors legal structure. Law is inherently hierarchical: jurisdictions contain courts, claims contain elements, transactions contain stages. Markdown's heading structure (H1 through H6) maps perfectly to this conceptual organization:
# Delaware Corporate Law

## Section 220: Stockholder Inspection Rights

### Subsection (b): Proper Purpose Requirement
- Must state purpose with specificity
- Purpose must relate to stockholder interest
- Burden shifts after showing proper form

### Subsection (c): Scope of Inspection
This hierarchy helps the LLM understand which concepts are primary, which are subordinate, and how they relate—critical for accurate legal analysis.

A Framework for AI-Optimized Markdown

Based on patterns that consistently improve AI performance, here's how to structure your legal prompts:

1. Hierarchical Organization with Headers

Use H2 (##) and H3 (###) headers to create clear information boundaries:
## Matter Context
- Case: [Name]
- Court: [Jurisdiction and Judge]  
- Claims: [Primary causes of action]
- Status: [Current procedural posture]

### Analysis Required
Review the attached contract for:
- **Material adverse change provisions** (Section 7.2)
- **Termination rights** (Section 8)
- **Indemnification scope** (Section 9)

### Output Format
Provide a table with three columns:
- Provision
- Standard Market Terms  
- Deviations/Concerns
2. Emphasis Signals

Bold key phrases to draw LLM attention:
The **critical deadline is November 15, 2025**. Any analysis must 
account for the fact that **we represent the defendant, not plaintiff**,
and our strategy emphasizes **forum non conveniens as the threshold issue**.
3. Lists for Enumeration

Use bullets for parallel items, numbered lists for sequences:
Key witnesses identified:
- Jane Smith (CFO): financial projections
- Robert Jones (General Counsel): merger negotiations  
- Maria Garcia (Board Member): approval process

Document review sequence:
1. Pull all board materials from 2023-2024
2. Identify references to "Project Titan"
3. Cross-reference with email productions
4. Flag any privilege issues
4. Code Blocks for Preservation

Use code blocks (triple backticks) when you need exact formatting preserved—particularly useful for statutory text, contract language, or specific output formats you want the LLM to follow:
The relevant statutory language states:

```
§ 220. Inspection of books and records.
(b) Any stockholder... shall, upon written demand under oath 
stating the purpose thereof, have the right during the usual 
hours for business to inspect for any proper purpose...
```

Please analyze how this language supports our inspection demand.
Requesting structured markdown responses: While many AI tools default to markdown output, you can explicitly request it for better structure. This specification does two things: it tells the LLM exactly what structure you want, and it primes the model to think systematically about organizing its response.

Speaking the Language of AI

Markdown amplifies the context engineering principles we've explored in this series. The structured syntax ensures your carefully built context gets interpreted correctly. Headers preserve the hierarchy you've designed. Lists maintain the relationships you've defined. Bold text guides the LLM's attention to what matters most.

Think of markdown as the transmission protocol for the context you've engineered. You've learned to build sophisticated information architectures with matter context, strategic context, and task context. Markdown ensures that architecture arrives intact, with every signal you intended preserved and understood.

As you continue building reusable prompt libraries and refining your AI workflows, markdown becomes invisible infrastructure. Eventually this approach will become second nature. You'll stop thinking about the syntax and start thinking purely about structure and meaning. That's when markdown has truly become your lingua franca with AI systems.

For more on building reusable context documents, revisit our post on Building Prompt Libraries. The combination of structured markdown syntax and persistent document repositories creates sophisticated AI-enhanced legal workflows.

---

Questions about markdown or other AI tools? Visit the Human Center AI support page or contact the Innovation Team at GIO_Support@freshfields.com. If you need any technical support, the Global IT Service Desk is available via the Service Portal or at +44 161 880 6666.
</post_11>

<post_12>
Let's Talk About Verification

 

Over the past several weeks, we've explored how to maximize AI effectiveness through context engineering—building sophisticated information architectures, using markdown for structure, applying priming and planning techniques. We've focused on getting better inputs to generate better outputs.

 

Now we address the other half of the equation: ensuring those outputs are actually correct.

 

Building sustainable, professional-grade workflows that deliver real value requires confronting verification head-on. As Sundar Pichai, CEO of Google's parent company Alphabet, recently told the BBC: people should not "blindly trust" everything AI tools tell them. AI models are "prone to errors," and we must use them alongside other tools and verification processes.

 

The Verification-Value Equation

 

Andrej Karpathy, former director of AI at Tesla and OpenAI, frames the current era this way: "We're now cooperating with AIs. They're doing the generation and we, as humans, are doing the verification. It is in our interest to make this loop go as fast as possible."

 

But how fast can that loop actually go in legal practice?

 

A forthcoming Law Review article, "The Verification-Value Paradox: A Normative Critique of Gen AI Use in Legal Practice" by Joshua Yuvaraj, proposes a formula that reframes how we should think about AI value in professional services:

 

N = EG − VC

 

Where N is Net Value, EG is Efficiency Gain, and VC is Verification Cost.

 

The efficiency gains from AI generation are real—a brief that might take 10 hours to draft can be generated in 10 minutes. But if verification requires 9 hours and 50 minutes of forensic review to ensure every citation exists, every fact is accurate, and every legal argument is sound, the net value approaches zero.

 

This isn't hypothetical. Courts have sanctioned lawyers for submitting AI-generated briefs with hallucinated cases. Regulatory bodies have referred practitioners for using unverified AI outputs. The professional and reputational costs of verification failures are severe.

 

The well-known tech leader/investor Balaji Srinivasan puts it directly: "The question when using AI is: how can I inexpensively verify the output of this AI model is correct? We take for granted the human eye, which is amazing at finding errors in images, videos, and user interfaces. But we need other kinds of verifiers for other domains."

 

For legal work, we need verification systems tailored to our domain's demands.

 

The Verification Challenge: Three Realities

 

Reality 1: We Need Systems and Infrastructure

 

Individual lawyer vigilance is necessary but insufficient. We need systematic approaches that make verification efficient enough to preserve net value.

 

This means building infrastructure:

 

Verification checklists tailored to specific workflows
 

Tools that assist verification (not just generation)
 

Clear protocols for what requires verification and at what level
 

Training focused on verification skills, not just prompting skills
 

Implication: Firms must invest in verification infrastructure alongside scaling AI adoption. Without these systems, efficiency gains disappear into verification costs.


Reality 2: Verification Must Be Continuous, Not Terminal

 

Traditional workflow: draft → complete → review → finalize.

 

AI-augmented workflow requires a different model. Verification cannot wait until after a week of AI-assisted work. By then, errors may be deeply embedded in analysis, and the cost of unwinding them approaches the cost of starting over.

 

Instead, verification needs to happen continuously:

 

Micro-verification: Checking individual outputs as they're generated; notably, context used as background needs to be verified.
 

Checkpoint verification: Validating at key workflow stages
 

Final verification: Comprehensive review before work product leaves your control
 

Implication: This distributed verification model changes the rhythm and cadence of legal work—from long stretches of heads-down drafting to iterative cycles of generation and validation.

 

Reality 3: Verification Requires Judgment

 

The instinct when AI generates a draft is to hand it to a junior colleague for review. This makes intuitive sense—reviewing is traditionally junior work.

 

But verification of AI outputs is fundamentally different.

 

When reviewing human work, you're checking another professional's output—someone who followed a recognizable analytical framework and can explain their reasoning. When verifying AI outputs, you're checking whether the AI invented facts, hallucinated citations, or fabricated plausible-sounding but incorrect legal reasoning.

 

Junior colleagues can excel as context engineers—building the sophisticated inputs we've discussed in recent posts. But verification requires judgment: the discernment and taste to recognize when something sounds right but is wrong. This is a senior-level skill.

 

Implication: Verification is mid-to-senior level work. This fundamentally changes staffing models, talent deployment, and the economics of legal service delivery.

 

Where We Go From Here

 

The context engineering approaches we've explored in recent posts—structured information architectures, persistent document repositories, systematic prompt libraries—all improve output quality. Better inputs reduce verification burden, but they don't eliminate it.

 

Verification infrastructure must develop in parallel with generation capabilities. The firms that recognize this will build sustainable competitive advantages. Those that focus only on generation speed will discover the verification-value paradox firsthand.

 

We'll explore practical verification systems, tools, and workflows in upcoming posts. For now, the essential insight: verification is the foundation for professional, sustainable AI use.

 

---

 

Questions about verification workflows or AI tools? Contact the Innovation Team at GIO_Support@freshfields.com. For technical support, reach the Global IT Service Desk via the Service Portal or at +44 161 880 6666.
</post_12>

<post_13>
For (Outside) Googlers: 5 Reasons to Use Gemini

As an initial matter, we have tremendous AI capabilities now available to everyone across the firm. In recent updates, Microsoft Copilot has incorporated GPT-5, and the Freshfields AI Toolkit has added Tabular Review and Chat has been updated to run GPT-5.1, the latest and greatest frontier model from OpenAI. We all have access to powerful capabilities that continue to advance.

If you're on Google Workspace, you have access to additional state-of-the-art capabilities through Gemini. Google announced Gemini 3 on November 18, 2025, dominating the benchmarks on nearly all metrics. The significance for professional work: better context understanding and intent recognition. You spend less time explaining what you need—the AI understands faster and responds smarter.

Here are five reasons to make the most of your access.

1. Always Use the Best Model Available

Right now, that's Gemini 3.0, especially Gemini 3.0 Pro and Gemini 3.0 Thinking Mode.

Push these models hard. Test them with work that feels challenging or even impossible. The models are more capable than you think, and the only way to discover their limits is to see how far into a task they can go.

Don't hold back. You'll be surprised how much they can handle.

2. Use Canvas for Drafting and More

Canvas is Gemini's split-screen workspace where AI outputs persist as editable artifacts alongside your conversation. Unlike chat responses that scroll away, Canvas gives you a dedicated document you can iterate on.

For drafting, Canvas unlocks true co-creation—fundamentally different from chat. This is a glimpse into how you'll draft in the future—working with AI in a persistent workspace rather than through ephemeral conversation.

But drafting isn't the only use. For the kind of work you're generally doing, you should be thinking about using Canvas. 

This approach has several benefits:

Revise without regenerating - Edit directly rather than asking AI to recreate everything

Offload from memory - Canvas artifacts don't consume the conversation's token limit and persist if long chats are compacted

Easy to find - Return to previous canvases rather than scrolling through chat history

Simple export - Download or copy (or cut + paste) formatted content seamlessly

Make Canvas part of your process. Get into the habit of requesting responses in Canvas, then modifying that canvas rather than continuing in chat.

3. Deep Research for Professional-Grade Work

Deep Research is an agent. You provide a question and context, and the agent breaks your query into dozens, perhaps even 100+ research questions. It goes out, conducts the research, and synthesizes a comprehensive response.

This process runs long. Expect a 30-minute wait time, but for work that would take a single person several weeks to complete. The output: polished, well-cited reports that dive deep into your subject matter and can stretch to dozens of pages.

Most professional work requires this level of depth, not quick answers. Use it for:

Memoranda preparation
Financial, scientific, and policy analysis
Transaction market research
Regulatory landscape mapping

Anywhere depth matters, Deep Research should be your default approach.

4. Deep Research on Files!

Now point that same capability at your Google Drive or local folders. Deep Research works on your documents, not just the web. The same agentic process—breaking queries into multiple research questions, synthesizing comprehensive analysis—applies to your case documents, precedents, and internal research libraries.

This won't draft a brief; it is deep research. But what used to require weeks of manual review becomes hours of agent-driven synthesis. It isn't hard to imagine where this kind of capability goes from here. You're getting a taste of the agentic future.

5. Image Generation for Visual Communication

PowerPoint presentations. Trial graphics. Expert reports with graphs. Visualizations are already part of your regular work. Now you have access to professional-quality image generation at essentially zero cost.

Sometimes a picture is worth a thousand words. A well-placed, compelling diagram or image can have lasting impact. Nano Banana Plus (Google's latest image generation model) integrates directly into your workflow via the Gemini app. Create, iterate, refine—all without external designers or delays.

Bonus: Voice

Speak directly to Gemini using the Google Voice button in the interface. AI cleanup and understanding happen under the hood, making your spoken queries more accurately interpreted.

As I've previously recommended with Voice Access for Windows, speaking to AI tools can be more effective than a carefully crafted prompt for many tasks.

Share What You Learn

These features—or variations—will eventually become standard across the firm. The Google Workspace team has an opportunity to experiment early and build expertise. 

More importantly: share your insights. Document what works and what doesn't. Help colleagues understand what's coming. You're building institutional knowledge about the future of legal work. That knowledge benefits everyone.

Reminders

You must have explicit client approval to use Google Workspace and Gemini for client work.

Remember to always fact-check legal research and confirm that you may use AI for specific clients and client matters.

Please refer to Responsible Use of AI SharePoint and the Global IT Use Policy for all guidelines.

---

Questions about Gemini or other AI tools? Visit the support page or contact the Innovation Team at GIO_Support@freshfields.com. If you need any technical support, the Global IT Service Desk is available via the Service Portal or at +44 161 880 6666.
</post_13>

<post_14>
Verification in Practice: 5 Basic Steps

 

Last week in Let's Talk About Verification, we made the case that verification is the foundation for professional, sustainable AI use—something we must address head-on rather than hope will sort itself out. We explored the verification paradox, where verification costs can consume efficiency gains if we're not careful. We discussed why verification requires judgment and infrastructure, not just vigilance.

 

But what does verification actually look like in daily practice? The firm's AI Verification Guidelines (October 2025) provide the definition: verification means checking every AI-generated sentence or data point to ensure they are complete, accurate, and not misleading (including by omission).

 

The guidelines formalize what we've always known: verification isn't optional. All AI outputs relied upon must be verified in full—every sentence, every data point. This reflects our "human-centered AI" principle where lawyers remain in control. AI handles the legwork, not the brainwork.

 

We've identified five basic steps that help implement these requirements. You don't need all five every time—depth should match the stakes. These methods aren't perfect, but they're a practical starting point.

 

1. Iterate and Refine

 

The simplest verification method is also the most natural: read the AI's response, think about whether it addresses your need, and if not, refine your request. This iterative dialogue catches obvious errors and misalignments quickly.

 

Don't accept the first output as final. Each iteration is a chance to spot issues—a misunderstood instruction, an overlooked requirement, a factual inconsistency. The conversation itself becomes your first line of verification. While improving the output, you also validate through progressive refinement.

 

2. Request Self-Reflection

 

AI models can evaluate their own outputs when prompted. After receiving a response, ask the AI to review its work: "Double-check your analysis for accuracy" or "Are there any potential issues with this approach?" This self-reflection often surfaces uncertainties the model initially glossed over.

 

You can also request the AI include supporting information in its response—relevant excerpts, calculation steps, or reasoning chains. This transparency makes verification easier by exposing the model's thinking. When you can see how the AI arrived at its conclusion, you can better judge whether that path was sound.

 

3. Get a Second Opinion

 

Pass the same prompt and context plus the output to a different AI model. If Freshfields Chat drafted your memo, have Copilot review it. If you used Tabular Review to analyze a group of contracts, ask Google NotebookLM to validate the findings. Different models have different training data and biases—discrepancies between their outputs flag areas requiring human review. The guidelines specifically suggest using multiple AI tools to assist verification.

 

This approach works particularly well for complex work. When two models independently reach the same conclusion, confidence increases. When they diverge, you know exactly where to focus your verification efforts.

 

4. Verify Citations and Sources

 

Some AI systems provide citations automatically; others will generate them on request. Either way, check them. Every case name, every statute reference, every quoted passage needs validation. For legal work in particular, verification is fundamental. The guidelines mandate checking not just that sources exist, but that they're accessible, relevant, authoritative, and actually support the stated point.

 

The good news: citation verification is binary and straightforward. The case either exists or it doesn't. The quote either matches the source or it doesn't. This mechanical verification can often be delegated to junior team members or even automated through legal research platforms. Just ensure someone actually does it.

 

5. Apply Expert Review

 

Often, all that's needed is a careful, close read by someone who deeply understands the subject matter. If you've built the right context and achieved genuine understanding of your matter, a thorough review catches most issues. 

 

The key qualifier: "someone who deeply understands." The guidelines clarify that while verification tasks like fact-checking can be delegated to juniors, verifying legal interpretation requires qualified, experienced lawyers. The reviewer must possess sufficient expertise to recognize when something sounds plausible but is actually wrong.

 

Document Your Verification

 

One critical requirement that underpins all these steps: keep a record. The guidelines mandate that anyone using AI tools must maintain clear documentation of sources checked and steps taken to validate outputs.

 

Your verification record doesn't need to be elaborate. Note which sources you checked, what methods you used, and any issues you identified and resolved. If you delegated verification tasks, document who did what. This trail proves due diligence and helps others understand the work's reliability. Think of it as the modern equivalent of keeping research notes—essential professional practice in the AI era.

 

Building From Here

 

These steps provide practical methods for implementing the firm's verification requirements. Every practice area will develop specialized approaches suited to its workflows. Document-heavy transactional practices might emphasize systematic cross-referencing. Litigation teams might focus on precedent validation. Regulatory practices might prioritize compliance checking.

 

The guidelines establish the framework; these methods are just one way to meet those standards. What verification approaches have worked in your practice? What challenges remain unsolved? This is an evolving area where we can all learn from each other's experiences.

 

The conversation about effective verification has just begun. Share your approaches, your successes, and even your failures. The firms that develop efficient, robust verification practices—meeting our professional standards while preserving AI's efficiency gains—will be the ones that capture AI's full value.
</post_14>